{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import pprint\n",
    "import time\n",
    "from abc import abstractmethod, ABC\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict\n",
    "from typing import List\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from dotenv import load_dotenv\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "# from loguru import logger\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.trial import FrozenTrial\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    roc_curve,\n",
    "    log_loss,\n",
    "    matthews_corrcoef,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    average_precision_score\n",
    ")\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Bundle:\n",
    "    X: pd.DataFrame\n",
    "    y: pd.Series\n",
    "    ids: pd.DataFrame\n",
    "    positives: int\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelResult:\n",
    "    model_info: Dict[str, Any]\n",
    "    result_df: pd.DataFrame\n",
    "    hyper_params: Dict[str, Any]\n",
    "    pipelines: List[Pipeline]\n",
    "\n",
    "    def metrics(self) -> Dict[str, float]:\n",
    "        return self.model_info.get(\"additional\", {}).get(\"metrics\", {})\n",
    "\n",
    "    def get_trials(self) -> int:\n",
    "        return self.model_info.get(\"additional\", {}).get(\"study_trials\", -1)\n",
    "\n",
    "    def set_trials(self, n_trails: int):\n",
    "        self.model_info.setdefault(\"additional\", {})[\"study_trials\"] = n_trails\n",
    "\n",
    "\n",
    "class ModelTrainer(ABC):\n",
    "    @abstractmethod\n",
    "    def evaluate(\n",
    "            self,\n",
    "            bundle: Bundle,\n",
    "            hyper_params: Dict[str, Any],\n",
    "            n_splits: int,\n",
    "            compute_shap: bool = False,\n",
    "    ) -> ModelResult:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "base_path = os.environ.get('BASE_PATH', '/kaggle/input/icr-identify-age-related-conditions')\n",
    "\n",
    "train = pd.read_csv(f'{base_path}/train.csv')\n",
    "test = pd.read_csv(f'{base_path}/test.csv')\n",
    "greeks = pd.read_csv(f'{base_path}/greeks.csv')\n",
    "# sample_submission = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')\n",
    "\n",
    "num_cols = test.select_dtypes(include=['float64']).columns.tolist()\n",
    "cat_cols = test.select_dtypes(include=['object']).columns.tolist()\n",
    "cat_cols.remove('Id')\n",
    "\n",
    "TARGET_COL = \"Class\"\n",
    "\n",
    "\n",
    "def weighted_log_loss(y_true, y_pred) -> float:\n",
    "    return log_loss(\n",
    "        y_true, y_pred, sample_weight=compute_sample_weight(\"balanced\", y_true)\n",
    "    )\n",
    "\n",
    "\n",
    "def weighted_matthews_corrcoef(y_true, y_pred) -> float:\n",
    "    return matthews_corrcoef(\n",
    "        y_true, y_pred, sample_weight=compute_sample_weight(\"balanced\", y_true)\n",
    "    )\n",
    "\n",
    "\n",
    "def balanced_precision_recall(y_true, y_pred) -> float:\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    return ((precision + recall) - abs(precision - recall)) / 2\n",
    "\n",
    "\n",
    "def balanced_weighted_log_loss(y_true, y_pred, eps=1e-15):\n",
    "    # Compute class prevalences\n",
    "    prevalence_0 = np.mean(1 - y_true)\n",
    "    prevalence_1 = np.mean(y_true)\n",
    "\n",
    "    # Compute weights\n",
    "    weight_0 = 1 / prevalence_0\n",
    "    weight_1 = 1 / prevalence_1\n",
    "\n",
    "    # Cap predicted probabilities\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "\n",
    "    # Compute log loss for each class\n",
    "    # np.mean() function is taking care of dividing by N0 and N1\n",
    "    log_loss_0 = -np.mean((1 - y_true) * np.log(1 - y_pred))\n",
    "    log_loss_1 = -np.mean(y_true * np.log(y_pred))\n",
    "\n",
    "    # Combine the log losses\n",
    "    total_log_loss = weight_0 * log_loss_0 + weight_1 * log_loss_1\n",
    "\n",
    "    return float(total_log_loss / (weight_0 + weight_1))\n",
    "\n",
    "\n",
    "def youdens_index(y_true, y_score):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "    youdens_index = tpr - fpr\n",
    "    return float(thresholds[np.argmax(youdens_index)])\n",
    "\n",
    "\n",
    "def max_roc_distance(y_true, y_score):\n",
    "    # maximizes the distance to the line of no-discrimination (diagonal line) in the ROC space.\n",
    "    # Calculation maximizes the geometric mean of sensitivity and specificity.\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "    gmeans = np.sqrt(tpr * (1 - fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "    return float(thresholds[ix])\n",
    "\n",
    "\n",
    "SCORERS = {\n",
    "    \"roc_auc_score\": (roc_auc_score, True),\n",
    "    \"recall_score\": (recall_score, False),\n",
    "    \"precision_score\": (precision_score, False),\n",
    "    \"f1_score\": (f1_score, False),\n",
    "    \"log_loss\": (log_loss, True),\n",
    "    \"weighted_log_loss\": (weighted_log_loss, True),\n",
    "    \"balanced_weighted_log_loss\": (balanced_weighted_log_loss, True),\n",
    "    \"accuracy_score\": (accuracy_score, False),\n",
    "    \"matthews_corrcoef\": (weighted_matthews_corrcoef, False),\n",
    "    \"balanced_precision_recall\": (balanced_precision_recall, False),\n",
    "    \"average_precision_score\": (average_precision_score, True),\n",
    "}\n",
    "\n",
    "OPTIMIZATION_OBJECTIVES = [\n",
    "    (\"minimize\", \"balanced_weighted_log_loss\"),\n",
    "    # (\"minimize\", \"log_loss\"),\n",
    "    # (\"maximize\", \"balanced_precision_recall\"),\n",
    "]\n",
    "\n",
    "SCORING = OPTIMIZATION_OBJECTIVES[0][1]\n",
    "\n",
    "MODEL_TYPE = \"xgboost\"\n",
    "\n",
    "TAKE_TOP_FEATURES = 10\n",
    "\n",
    "VERSION = f\"{datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}\"\n",
    "\n",
    "\n",
    "def build_feature_transformer() -> ColumnTransformer:\n",
    "    numerical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "    # categorical_transformer = Pipeline(\n",
    "    #     steps=[\n",
    "    #         (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    #     ]\n",
    "    # )\n",
    "    if MODEL_TYPE == \"xgboost\":\n",
    "        categorical_transformer = Pipeline(\n",
    "            steps=[\n",
    "                (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "                (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "            ]\n",
    "        )\n",
    "    elif MODEL_TYPE == \"lightgbm\":\n",
    "        categorical_transformer = Pipeline(\n",
    "            steps=[\n",
    "                (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"{MODEL_TYPE} must be xgboost or lightgbm\")\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numerical_transformer, num_cols),\n",
    "            (\"cat\", categorical_transformer, cat_cols),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def build_pipeline(params: Dict[str, Any] | None = None, scale_pos_weight: float = 1.0) -> Pipeline:\n",
    "    if MODEL_TYPE == \"xgboost\":\n",
    "        if params:\n",
    "            #\n",
    "            clf = xgb.XGBClassifier(\n",
    "                objective=\"binary:logistic\",\n",
    "                tree_method=\"hist\",\n",
    "                enable_categorical=True,\n",
    "                # scale_pos_weight=scale_pos_weight,\n",
    "                **params,\n",
    "            )\n",
    "        else:\n",
    "            clf = xgb.XGBClassifier(\n",
    "                objective=\"binary:logistic\", tree_method=\"hist\", enable_categorical=True,\n",
    "                # scale_pos_weight=scale_pos_weight,\n",
    "            )\n",
    "    elif MODEL_TYPE == \"lightgbm\":\n",
    "        clf = lgb.LGBMClassifier()\n",
    "        if params:\n",
    "            clf.set_params(**params)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"unknown model type {MODEL_TYPE}\")\n",
    "\n",
    "    pipeline = ImbPipeline(\n",
    "        [\n",
    "            (\n",
    "                \"preprocessor\",\n",
    "                build_feature_transformer(),\n",
    "            ),\n",
    "            (\"smote\", SMOTE(random_state=42)),\n",
    "            (\"classifier\", clf),\n",
    "        ]\n",
    "    )\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def prepare_eval_X(X_train, X_test):\n",
    "    eval_feature_transformer = build_feature_transformer()\n",
    "    eval_feature_transformer.fit(X_train, X_test)\n",
    "    X_eval = eval_feature_transformer.transform(X_test)\n",
    "    return X_eval\n",
    "\n",
    "\n",
    "class GradientBoosterTrainer(ModelTrainer):\n",
    "    def train(self, params: Dict[str, Any], X, y) -> Pipeline:\n",
    "        pipeline = build_pipeline(params=params)\n",
    "        pipeline.fit(\n",
    "            X,\n",
    "            y\n",
    "        )\n",
    "        return pipeline\n",
    "\n",
    "    def evaluate(\n",
    "            self,\n",
    "            bundle: Bundle,\n",
    "            hyper_params: Dict[str, Any],\n",
    "            n_splits: int,\n",
    "            compute_shap: bool = False,\n",
    "    ) -> ModelResult:\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        metrics = defaultdict(list)\n",
    "        X = bundle.X\n",
    "        y = bundle.y\n",
    "        ids_list = []\n",
    "        predictions = []\n",
    "        print(f\"Starting evaluation on {n_splits} splits\")\n",
    "        negative = int((bundle.y == 0).sum())\n",
    "        positive = int((bundle.y == 1).sum())\n",
    "        scale_pos_weight = negative / positive\n",
    "        pipelines = []\n",
    "        for train_index, test_index in cv.split(X, y):\n",
    "            print(f\"Fitting model on split: {len(ids_list)}\")\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            ids_test = bundle.ids.values[test_index]\n",
    "            pipeline = build_pipeline(params=hyper_params, scale_pos_weight=scale_pos_weight)\n",
    "            pipeline.fit(\n",
    "                X_train,\n",
    "                y_train,\n",
    "                classifier__early_stopping_rounds=20,\n",
    "                classifier__eval_metric=[\"logloss\"],\n",
    "                classifier__eval_set=[(prepare_eval_X(X_train, X_test), y_test)],\n",
    "                classifier__verbose=False,\n",
    "            )\n",
    "            best_iteration = pipeline['classifier'].best_iteration\n",
    "            best_score = pipeline['classifier'].best_score\n",
    "            print(f'best iter {best_iteration}. best score {best_score}')\n",
    "            pipelines.append(pipeline)\n",
    "            y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "            predictions.extend(y_pred_proba)\n",
    "            y_pred = y_pred_proba > 0.5\n",
    "\n",
    "            for metric_name, (fscore, needs_proba) in SCORERS.items():\n",
    "                metrics[metric_name].append(\n",
    "                    fscore(y_test, y_pred_proba if needs_proba else y_pred)\n",
    "                )\n",
    "\n",
    "            ids_list.append(ids_test)\n",
    "\n",
    "        result_df = pd.DataFrame(\n",
    "            bundle.ids, columns=[\"Id\", \"Class\"]\n",
    "        )\n",
    "        # '', ''\n",
    "        result_df[\"class_0\"] = predictions\n",
    "        result_df[\"class_1\"] = [1 - prob for prob in predictions]\n",
    "        # result_df[\"status\"] = []\n",
    "\n",
    "        metrics = {k: np.mean(v) for k, v in metrics.items()}\n",
    "\n",
    "        additional = {\n",
    "            \"model_type\": MODEL_TYPE,\n",
    "            \"metrics\": metrics,\n",
    "            \"optimization_objectives\": [obj for _, obj in OPTIMIZATION_OBJECTIVES],\n",
    "            \"hyper_prams\": hyper_params.copy(),\n",
    "            \"youden_index\": youdens_index(y, predictions),\n",
    "            \"max_gmeans_roc\": max_roc_distance(y, predictions),\n",
    "        }\n",
    "\n",
    "        info_record = {\n",
    "            k: v\n",
    "            for k, v in metrics.items()\n",
    "            if k\n",
    "               in {\n",
    "                   \"balanced_weighted_log_loss\",\n",
    "                   \"recall_score\",\n",
    "                   \"precision_score\",\n",
    "                   \"roc_auc_score\",\n",
    "                   \"accuracy_score\",\n",
    "                   \"f1_score\"\n",
    "               }\n",
    "        }\n",
    "\n",
    "        info_record[\"class_0\"] = negative\n",
    "        info_record[\"class_1\"] = positive\n",
    "        info_record[\"scale_pos_weight\"] = scale_pos_weight\n",
    "        print(f\"Negative/Positive: {scale_pos_weight}\")\n",
    "        print(f\"Calculated model metrics:\\n{pprint.pformat(metrics)}\")\n",
    "\n",
    "        info_record[\"additional\"] = additional\n",
    "        info_record[\"model_version\"] = VERSION\n",
    "\n",
    "        # if compute_shap:\n",
    "        #     info_record[\"features\"] = json.dumps(model_shap)\n",
    "        #     features_df = pd.concat(customers_shap)\n",
    "        #     result_df = result_df.merge(features_df, on=[\"customer_id\"])\n",
    "\n",
    "        return ModelResult(\n",
    "            model_info=info_record, result_df=result_df, hyper_params=hyper_params, pipelines=pipelines\n",
    "        )\n",
    "\n",
    "\n",
    "def preprocess_input(df: pd.DataFrame) -> Bundle:\n",
    "    # df[\"label\"] = [1 if l == \"churned\" else 0 for l in df.label.values]\n",
    "    # positives = len(df[df.label == 1].index)\n",
    "    # effective_date = df.effective_date.values[0]\n",
    "    drop_cols = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if col not in cat_cols + num_cols\n",
    "    ]\n",
    "    X = df.drop(columns=drop_cols)\n",
    "    print(\"X features:\")\n",
    "    print(X.columns)\n",
    "    return Bundle(\n",
    "        X=X,\n",
    "        y=df[TARGET_COL],\n",
    "        ids=df[\"Id\"],\n",
    "        positives=len(df[df[TARGET_COL] == 1].index)\n",
    "    )\n",
    "\n",
    "\n",
    "class HyperparametersOptimizer:\n",
    "    def __init__(self, model: GradientBoosterTrainer, scaling_factor: float = 5000):\n",
    "        self.model: ModelTrainer = model\n",
    "        self.scaling_factor = scaling_factor\n",
    "\n",
    "    def objective(self, trial, bundle: Bundle, n_splits: int, objectives: List[str]):\n",
    "        if MODEL_TYPE == \"xgboost\":\n",
    "            param = {\n",
    "                \"n_estimators\": trial.suggest_int(\"n_estimators\", 75, 200),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 5, 15),\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1),\n",
    "                \"subsample\": trial.suggest_float(\"subsample\", 0.2, 0.8),\n",
    "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 0.8),\n",
    "                \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 30),\n",
    "                \"gamma\": trial.suggest_float(\"gamma\", 0, 1),\n",
    "                \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-7, 1e-2),\n",
    "                \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-7, 1e-2),\n",
    "            }\n",
    "\n",
    "        elif MODEL_TYPE == \"lightgbm\":\n",
    "            param = {\n",
    "                \"classifier__n_estimators\": trial.suggest_int(\"n_estimators\", 35, 150),\n",
    "                \"classifier__max_depth\": trial.suggest_int(\"max_depth\", 5, 12),\n",
    "                \"classifier__learning_rate\": trial.suggest_uniform(\n",
    "                    \"learning_rate\", 0.001, 0.1\n",
    "                ),\n",
    "                \"classifier__subsample\": trial.suggest_uniform(\"subsample\", 0.2, 0.8),\n",
    "                \"classifier__colsample_bytree\": trial.suggest_uniform(\n",
    "                    \"colsample_bytree\", 0.2, 0.9\n",
    "                ),\n",
    "                \"classifier__min_child_weight\": trial.suggest_int(\n",
    "                    \"min_child_weight\", 1, 7\n",
    "                ),\n",
    "                \"classifier__num_leaves\": trial.suggest_int(\"num_leaves\", 20, 100),\n",
    "                \"classifier__reg_alpha\": trial.suggest_uniform(\"reg_alpha\", 0, 1),\n",
    "                \"classifier__reg_lambda\": trial.suggest_uniform(\"reg_lambda\", 0, 1),\n",
    "                \"classifier__feature_fraction\": trial.suggest_uniform(\n",
    "                    \"feature_fraction\", 0.4, 1.0\n",
    "                ),\n",
    "                \"classifier__bagging_fraction\": trial.suggest_uniform(\n",
    "                    \"bagging_fraction\", 0.4, 1.0\n",
    "                ),\n",
    "                \"classifier__min_child_samples\": trial.suggest_int(\n",
    "                    \"min_child_samples\", 5, 100\n",
    "                ),\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model_type. Must be 'xgboost' or 'lightgbm'.\")\n",
    "\n",
    "        # Perform cross-validation and take the mean of the scores\n",
    "        result = self.model.evaluate(\n",
    "            bundle=bundle, hyper_params=param, n_splits=n_splits, compute_shap=False\n",
    "        )\n",
    "        metrics = result.metrics()\n",
    "        scores = [metrics[objective] for objective in objectives]\n",
    "        print(f\"Trial {trial.number} CV {objectives}: {scores}\")\n",
    "        return tuple(scores)\n",
    "\n",
    "    def optimize_params(\n",
    "            self, bundle: Bundle, n_splits: int, n_trials=500\n",
    "    ) -> Dict[str, Any]:\n",
    "        sampler = TPESampler(seed=42)\n",
    "        print(f\"Objectives {OPTIMIZATION_OBJECTIVES}\")\n",
    "        directions, objectives = zip(*OPTIMIZATION_OBJECTIVES)\n",
    "        study = optuna.create_study(\n",
    "            directions=directions,\n",
    "            sampler=sampler,\n",
    "            pruner=optuna.pruners.MedianPruner(n_warmup_steps=10),\n",
    "            study_name=f\"icr-conditions-{VERSION}\",\n",
    "        )\n",
    "        print(\n",
    "            f\"Starting hyperparameters search. {n_trials} trials, {n_splits} cv splits\"\n",
    "        )\n",
    "        start = time.time()\n",
    "        study.optimize(\n",
    "            lambda trial: self.objective(trial, bundle, n_splits, objectives),\n",
    "            n_trials=n_trials,\n",
    "            show_progress_bar=True,\n",
    "        )\n",
    "        print(f\"Pareto Front\")\n",
    "\n",
    "        def aggregate_metrics(x: FrozenTrial):\n",
    "            print(f\"Trial {x.number} - values: {x.values}\")\n",
    "            return sum(\n",
    "                [\n",
    "                    v if directions[i] == \"maximize\" else -v\n",
    "                    for i, v in enumerate(x.values)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        best_trial = sorted(study.best_trials, key=lambda x: aggregate_metrics(x))[-1]\n",
    "\n",
    "        print(\n",
    "            f\"Hyperparameters search took {(time.time() - start) / 60} minutes.\"\n",
    "        )\n",
    "        print(f\"Best values: {pprint.pformat(best_trial.values)}\")\n",
    "        print(f\"Best hyper-parameters: {pprint.pformat(best_trial.params)}\")\n",
    "        return best_trial.params\n",
    "\n",
    "\n",
    "def find_by_randomized_cv_search(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        pipeline,\n",
    "        scoring: str = \"roc_auc\",\n",
    "        model_type: str = \"xgboost\",\n",
    "        n_iter=500,\n",
    "):\n",
    "    if model_type == \"xgboost\":\n",
    "        param_dist = {\n",
    "            \"classifier__n_estimators\": randint(35, 200),\n",
    "            \"classifier__max_depth\": randint(5, 12),\n",
    "            \"classifier__learning_rate\": uniform(0.001, 0.1),\n",
    "            \"classifier__subsample\": uniform(0.2, 0.8),\n",
    "            \"classifier__colsample_bytree\": uniform(0.2, 0.8),\n",
    "            \"classifier__min_child_weight\": randint(1, 30),\n",
    "            \"classifier__gamma\": uniform(0, 1),\n",
    "        }\n",
    "    elif model_type == \"lightgbm\":\n",
    "        param_dist = {\n",
    "            \"classifier__n_estimators\": randint(50, 300),\n",
    "            \"classifier__max_depth\": randint(3, 10),\n",
    "            \"classifier__learning_rate\": uniform(0.01, 0.3),\n",
    "            \"classifier__subsample\": uniform(0.5, 0.5),\n",
    "            \"classifier__colsample_bytree\": uniform(0.5, 0.5),\n",
    "            \"classifier__min_child_weight\": randint(1, 7),\n",
    "            \"classifier__num_leaves\": randint(20, 100),\n",
    "            \"classifier__reg_alpha\": uniform(0, 1),\n",
    "            \"classifier__reg_lambda\": uniform(0, 1),\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model_type. Must be 'xgboost' or 'lightgbm'.\")\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        scoring=scoring,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "    best_params = search.best_params_\n",
    "    best_params = {\n",
    "        key.replace(\"classifier__\", \"\"): value for key, value in best_params.items()\n",
    "    }\n",
    "    print(f\"Best parameters: {pprint.pformat(best_params)}\")\n",
    "    return best_params\n",
    "\n",
    "\n",
    "def run_main(\n",
    "        hp_trials: int = 500,\n",
    ") -> ModelResult:\n",
    "    model = GradientBoosterTrainer()\n",
    "    optimizer = HyperparametersOptimizer(model=model)\n",
    "    start = time.time()\n",
    "\n",
    "    print(f\"Loading features and labels version {VERSION}\")\n",
    "\n",
    "    bundle = preprocess_input(train)\n",
    "    \n",
    "    \n",
    "    hyper_params = {'colsample_bytree': 0.33052237200491763,\n",
    "                                'gamma': 0.44216411057904137,\n",
    "                                'learning_rate': 0.0869668401043195,\n",
    "                                'max_depth': 9,\n",
    "                                'min_child_weight': 3,\n",
    "                                'n_estimators': 196,\n",
    "                                'reg_alpha': 0.0042716453721107425,\n",
    "                                'reg_lambda': 0.006124657768172271,\n",
    "                                'subsample': 0.6486718367208028}\n",
    "    \n",
    "#     hyper_params = optimizer.optimize_params(\n",
    "#         bundle,\n",
    "#         n_splits=4,\n",
    "#         n_trials=hp_trials\n",
    "#     )\n",
    "    print(\n",
    "        f\"Training, Predicting\"\n",
    "    )\n",
    "    # test_splits = round(bundle.positives / 25)\n",
    "    test_splits = 5\n",
    "    model_result = model.evaluate(\n",
    "        bundle=bundle,\n",
    "        n_splits=test_splits,\n",
    "        hyper_params=hyper_params,\n",
    "        # compute_shap=True,\n",
    "    )\n",
    "    print(f'Model {VERSION} Info:')\n",
    "    print(pprint.pformat(model_result.model_info))\n",
    "    results_path = os.environ.get('RESULTS_PATH', None)\n",
    "    if results_path:\n",
    "        res_path = f'{results_path}/{VERSION}'\n",
    "        os.mkdir(res_path)\n",
    "        pd.DataFrame.from_records([model_result.model_info]).to_csv(f'{res_path}/model_info.csv')\n",
    "        model_result.result_df.to_csv(f'{res_path}/results.csv')\n",
    "        with open(f'{res_path}/pipeline.pkl', 'wb') as f:\n",
    "            pickle.dump(model_result.pipelines, f)\n",
    "        print(f\"Model for {VERSION} saved\")\n",
    "        \n",
    "    test_features = test.drop(columns=['Id'])\n",
    "    test_predictions = []\n",
    "    for model in model_result.pipelines:\n",
    "        proba = model.predict_proba(test_features)  # picking the probabilities for both classes\n",
    "        test_predictions.append(proba)\n",
    "\n",
    "    # convert list of arrays to 3D array and then take mean along axis 0\n",
    "    test_predictions = np.mean(np.array(test_predictions), axis=0)\n",
    "\n",
    "    # Create a submission dataframe and save it to a csv file\n",
    "    submission = pd.DataFrame(test_predictions, columns=['class_0', 'class_1'])\n",
    "    submission.insert(0, 'Id', test['Id'])\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "    print(f\"ICR Conditions Model Run Completed. Overall Execution Took: {(time.time() - start) / 60} minutes\")\n",
    "\n",
    "run_main(hp_trials=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
